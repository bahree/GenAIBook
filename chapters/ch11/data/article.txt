After years of progress toward health equity and poverty reduction, we are seeing a widening gap between countries and communities on nearly all metrics of global development. The development of new technologies and their application in resource-poor settings has been one way to address these gaps. It will take concerted action by governments, the private sector, philanthropies, and civil society to develop the solutions needed to regain footing on the Sustainable Development Goals that we use to track progress.

Since its inception, the Bill & Melinda Gates Foundation has focused, through its partnerships and grantmaking, on applying innovation to help accelerate progress, promote human potential, and address long-standing inequities. Working with our partners we continually scan the horizon for innovations, from drought-resistant seeds to mRNA vaccines, that can make an impact toward health and development goals.

By almost all estimations, rapid advances in artificial intelligence, or AI, will make AI technology broadly available and transformative across societies and economies, with the potential to fundamentally alter the way people communicate, work, learn, and improve their well-being. In the areas where the Gates Foundation works, it is easy to imagine powerful uses for AI in everything from speeding medical breakthroughs and addressing the impacts of climate change to boosting learning outcomes and increasing agricultural production for smallholder farmers. The foundation has invested in dozens of applications of machine learning to health and development use cases to date. More recently, the rapid development and availability of large language models, like ChatGPT, has fundamentally changed what may be possible using AI. Potential gains will only be realized if the technology is implemented with the beneficiaries participating in its development. The speed with which AI is being developed poses a moment of opportunity and risk—will their creation and application be inclusive, reflecting the needs of lower-income countries, or will they be applied inequitably and further the gaps we’ve seen?

Potential gains will only be realized if the technology is implemented with the beneficiaries participating in its development.

Earlier advances in technology have delivered uneven benefits in many parts of the world for a variety of reasons, but lack of access to innovation is the primary reason people in low-resource settings often do not see benefits in a timely, fair, and consistent fashion. Like any new set of technologies, it is vital to approach the potential uses of AI with care and caution, particularly from the perspective of populations who have historically been left behind in realizing the benefits of innovations. It is also critical to acknowledge the risks associated with the spread of misinformation and the potential misuse of information facilitated by AI. In the realm of health and development, where accurate and reliable information is essential, the consequences of misinformation can be particularly damaging. Intentional design and collaboration with those who stand to benefit are critical to innovation having the desired impact, which we measure in lives saved and opportunities provided for people to achieve their full potential.

The use of AI for development requires specific considerations because of the nature of how and where large language models have been created, as well as the perceptions which accompany them. These models are built around the analysis of large data sets combined with algorithms and statistical models to find and utilize patterns. Marginalized communities have not had a seat at the table to inform the models, so the statistical representations in these models may be less accurate than for regions with better-represented data. This makes error rates and the risk of perpetuating pre-existing biases for AI utilizing such data significantly more likely. There is a real risk associated with AI tools if caution and oversight are not exercised. If not properly managed, these tools can inadvertently reinforce biases, perpetuate existing inequalities, and propagate misinformation. We must intentionally work to mitigate these limitations.

Our focus on access and equity is fundamental to our current and future work with AI.

Recognizing both the potential benefits and risks of AI and its rapid development, in March 2023 the foundation established an internal Global AI Task Force to help serve as a coordinating mechanism to define the role of AI as it relates to the foundation’s work, recognizing the many facets of our work and the evolving nature of this technology. The task force was created to drive a responsible and organized approach to exploring the foundation’s engagement with AI usage and help map a way forward that is safe, ethical, and equitable. Additionally, the foundation is establishing an ethics and equity advisory committee drawn from outside experts which will share insights on program design, ethical AI practice, provide accountability within the organization and our grantees, and advise how best to guard against bias and unintended consequences.

Our focus on access and equity is fundamental to our current and future work with AI. We understand that introducing AI into resource-limited settings may present unique risks, and we are committed to mitigating these through continuous research, collaboration, and open communication with stakeholders. As the foundation engages in work that leverages the power of AI, we will be guided by a set of first principles that shape our initial approach and aligned with our core mission—to help create a world where every person has the opportunity to live a healthy, productive life. These principles will be refined and adapted as we engage with partners and other outside experts, as we learn based on experience, and as future developments in AI technology evolve.

First principles Adhere to our core values

The foundation is guided by a belief that all people, no matter the circumstance into which they are born, should be able to live a healthy life and reach their full potential. Our approach to the use of AI technology is therefore grounded in the need to promote greater equity and opportunity for resource-poor communities. AI can be a useful tool in advancing these goals—if its downsides are properly managed. Promote co-design and inclusivity

Low-income countries must not just be seen as beneficiaries or end-users of AI but as essential collaborators and partners in program design and uses. This means sharing insights, concerns, and information across organizations and geographies to drive AI use that is fit for purpose and contextually sensitive. We will approach the use of AI collaboratively and recognize that effective partnership must be intentional and inclusive. Acknowledging the limited availability of digital infrastructure in LMICs, maximizing the benefits of AI in these regions may present additional challenges. In keeping with our overall approach to innovation, we will invest in developing an evidence base for the responsible use of AI with, and for, communities and populations that stand to benefit from them. Proceed responsibly

We view our role to help ensure equitable use and access to AI tools. We acknowledge that proceeding responsibly requires an approach centered on compliance, inclusivity, and continuous improvement. To achieve this, we will leverage established legal regulations, industry standards, and ethical guidelines to navigate the complex landscape of AI applications for health and development uses. We will proceed in a step-wise fashion, starting with a confined set of use cases and gradually scaling up as the evidence base is built out. Address privacy and security

Privacy and security are essential when it comes to the use of AI, particularly given that it will likely increasingly be used in situations that involve sensitive personal information. It will be important to regularly conduct privacy and security assessments, ensure compliance with relevant regulations including data protection laws, implement transparency and accountability measures, and continually engage with stakeholders to improve systems. It will also be vital to ensure such practical measures have been taken in advance of collecting sensitive data based on informed consent, opt-out measures are provided, and materials are shared in appropriate local languages. Build for equitable access

Amid a rapid AI transformation, there are important questions on its equitable access, use, and addressing systemic inequity. A commitment to equitable access is not just about distribution but also about ownership, maintenance, and support for AI uses within the development context. Ensure transparency

Given the potential for companies to commercialize the use of AI tools, we understand the importance of approaching this work with transparency. All of our grants are a matter of public record. And we adhere to a conflict-of-interest policy that guides all our work. Data should be shared to the greatest extent possible as a public good to allow for continual testing, improvement, and innovation.

These are early days in the development of AI and its uses to better human health and development. We recognize the inherent risks involved with AI and the need to address them responsibly. We also look forward to exploring the opportunities to harness this revolution to overcome challenges that to date have been intractable. As we have done with emerging technologies and platforms like mRNA for vaccines and therapeutics, genetic sequencing for disease identification and tracking, and other transformational tools, we are engaged early and to bend the curve towards equity. We will have much more to say about this topic here and across foundation channels.